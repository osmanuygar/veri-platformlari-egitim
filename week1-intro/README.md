# Hafta 1: Veri DÃ¼nyasÄ±na GiriÅŸ

## ğŸ“š Ä°Ã§indekiler

1. [Veri Nedir?](#1-veri-nedir)
2. [Veri TÃ¼rleri ve SÄ±nÄ±flandÄ±rmasÄ±](#2-veri-tÃ¼rleri-ve-sÄ±nÄ±flandÄ±rmasÄ±)
3. [Veri KaynaklarÄ±](#3-veri-kaynaklarÄ±)
4. [Veri PlatformlarÄ±nÄ±n Tarihsel Evrimi](#4-veri-platformlarÄ±nÄ±n-tarihsel-evrimi)
5. [Pratik Uygulamalar](#5-pratik-uygulamalar)
6. [AlÄ±ÅŸtÄ±rmalar](#6-alÄ±ÅŸtÄ±rmalar)
7. [Kaynaklar](#7-kaynaklar)

---

## 1. Veri Nedir?

### 1.1 Temel TanÄ±m

**Veri (Data):** Ham gerÃ§ekler, sayÄ±lar, metinler veya gÃ¶zlemler. Tek baÅŸÄ±na anlamsÄ±z olabilir, iÅŸlendiÄŸinde anlam kazanÄ±r.

```
Veri â†’ Ä°ÅŸleme â†’ Bilgi â†’ Analiz â†’ Bilgi (Wisdom)
```

#### HiyerarÅŸi:
- **Veri:** 25, 30, 28
- **Bilgi:** Son 3 gÃ¼nÃ¼n sÄ±caklÄ±klarÄ±: 25Â°C, 30Â°C, 28Â°C
- **Bilgi:** Ortalama sÄ±caklÄ±k 27.6Â°C, artÄ±ÅŸ trendi var
- **Bilgi:** Klima aÃ§Ä±lmalÄ± ve enerji tasarrufu planÄ± yapÄ±lmalÄ±

### 1.2 GÃ¼nÃ¼mÃ¼zde Verinin Ã–nemi

#### Ä°statistikler:
- Her gÃ¼n dÃ¼nyada **2.5 exabyte** (2.5 milyon terabyte) veri Ã¼retiliyor
- DÃ¼nyadaki verinin **90%'Ä±** son 2 yÄ±lda Ã¼retildi
- 2025'te global veri hacmi **175 zettabyte**'a ulaÅŸacak
- Ä°ÅŸletmelerin **%80'i** veri odaklÄ± kararlar almak istiyor

#### Veri Neden DeÄŸerli?
1. **Rekabet AvantajÄ±:** Veriye dayalÄ± kararlar %5-6 daha fazla Ã¼retkenlik saÄŸlÄ±yor
2. **MÃ¼ÅŸteri Deneyimi:** KiÅŸiselleÅŸtirme ile %20 satÄ±ÅŸ artÄ±ÅŸÄ±
3. **Operasyonel Verimlilik:** Tahmine dayalÄ± bakÄ±m ile %12 maliyet tasarrufu
4. **Ä°novasyon:** Yeni Ã¼rÃ¼n ve hizmet geliÅŸtirme
5. **Risk YÃ¶netimi:** Fraud detection ve gÃ¼venlik

> "Veri 21. yÃ¼zyÄ±lÄ±n petrolÃ¼dÃ¼r" - Clive Humby

---

## 2. Veri TÃ¼rleri ve SÄ±nÄ±flandÄ±rmasÄ±

### 2.1 YapÄ±sal Veri (Structured Data)

**TanÄ±m:** Belirli bir ÅŸema ve formatta organize edilmiÅŸ, satÄ±r ve sÃ¼tunlardan oluÅŸan veri.

#### Ã–zellikler:
- âœ… Ã–nceden tanÄ±mlanmÄ±ÅŸ veri tipleri (integer, string, date)
- âœ… Ä°liÅŸkisel veritabanlarÄ±nda saklanÄ±r
- âœ… SQL ile kolayca sorgulanabilir
- âœ… Analiz ve raporlama kolay
- âŒ Esneklik dÃ¼ÅŸÃ¼k, ÅŸema deÄŸiÅŸiklikleri zor

#### Ã–rnekler:
```sql
-- MÃ¼ÅŸteri Tablosu
CREATE TABLE musteriler (
    id INT PRIMARY KEY,
    ad VARCHAR(50),
    soyad VARCHAR(50),
    email VARCHAR(100),
    dogum_tarihi DATE,
    bakiye DECIMAL(10,2)
);
```

**KullanÄ±m AlanlarÄ±:**
- Excel tablolarÄ±
- Ä°liÅŸkisel veritabanlarÄ± (MySQL, PostgreSQL)
- CRM sistemleri (Salesforce)
- ERP sistemleri (SAP)
- Finans kayÄ±tlarÄ±

### 2.2 YarÄ±-YapÄ±sal Veri (Semi-Structured Data)

**TanÄ±m:** KÄ±smen organize edilmiÅŸ, esnek ÅŸemalÄ± veri. Metadata veya etiketler iÃ§erir.

#### Ã–zellikler:
- âœ… Self-describing (kendi kendini tanÄ±mlayan)
- âœ… Esnek yapÄ±, ÅŸema deÄŸiÅŸiklikleri kolay
- âœ… HiyerarÅŸik veya nested yapÄ±lar
- âœ… NoSQL veritabanlarÄ±nda saklanabilir
- âŒ Geleneksel SQL ile sorgulamak zor olabilir

#### JSON Ã–rneÄŸi:
```json
{
  "musteri_id": 12345,
  "ad": "Ahmet",
  "soyad": "YÄ±lmaz",
  "iletisim": {
    "email": "ahmet@example.com",
    "telefon": "+90 532 123 4567",
    "adres": {
      "sehir": "Istanbul",
      "ilce": "Kadikoy",
      "posta_kodu": "34710"
    }
  },
  "siparisler": [
    {
      "siparis_no": "ORD-001",
      "tarih": "2025-01-15",
      "tutar": 450.00
    },
    {
      "siparis_no": "ORD-002",
      "tarih": "2025-01-20",
      "tutar": 230.50
    }
  ]
}
```

#### XML Ã–rneÄŸi:
```xml
<?xml version="1.0" encoding="UTF-8"?>
<musteri>
    <id>12345</id>
    <ad>Ahmet</ad>
    <soyad>YÄ±lmaz</soyad>
    <iletisim>
        <email>ahmet@example.com</email>
        <telefon>+90 532 123 4567</telefon>
    </iletisim>
</musteri>
```

**KullanÄ±m AlanlarÄ±:**
- JSON/XML dosyalarÄ±
- API yanÄ±tlarÄ±
- Log dosyalarÄ±
- Config dosyalarÄ±
- NoSQL veritabanlarÄ± (MongoDB)

### 2.3 YapÄ±sal Olmayan Veri (Unstructured Data)

**TanÄ±m:** Ã–nceden tanÄ±mlanmÄ±ÅŸ bir yapÄ±sÄ± olmayan, serbest format veri.

#### Ã–zellikler:
- âœ… En yaygÄ±n veri tÃ¼rÃ¼ (%80-90)
- âœ… Zengin iÃ§erik (metin, gÃ¶rÃ¼ntÃ¼, ses, video)
- âŒ Analiz etmek zor ve maliyetli
- âŒ Depolama gereksinimi yÃ¼ksek
- âŒ Geleneksel veritabanlarÄ±nda saklanamaz

#### Ã–rnekler:
1. **Metinsel Ä°Ã§erik:**
   - E-postalar
   - Word belgeleri
   - PDF dosyalarÄ±
   - Sosyal medya gÃ¶nderileri
   - Blog yazÄ±larÄ±

2. **Multimedya:**
   - FotoÄŸraflar
   - Videolar
   - Ses kayÄ±tlarÄ±
   - Podcast'ler

3. **DiÄŸer:**
   - PowerPoint sunumlarÄ±
   - TarayÄ±cÄ± geÃ§miÅŸi
   - IoT sensor ham verileri

**Teknolojiler:**
- Object Storage (AWS S3, Azure Blob)
- Data Lake
- Full-text search (Elasticsearch)
- Computer Vision (gÃ¶rÃ¼ntÃ¼ analizi)
- NLP (doÄŸal dil iÅŸleme)

### 2.4 KarÅŸÄ±laÅŸtÄ±rma Tablosu

| Ã–zellik | YapÄ±sal | YarÄ±-YapÄ±sal | YapÄ±sal Olmayan |
|---------|---------|--------------|-----------------|
| **Åema** | Sabit | Esnek | Yok |
| **Depolama** | RDBMS | NoSQL, Files | Object Storage, Data Lake |
| **Sorgulama** | SQL | JSON/XML parsers | Full-text search, AI |
| **Oran** | ~10% | ~10% | ~80% |
| **Analiz** | Kolay | Orta | Zor |
| **Ã–rnek** | Excel | JSON | Video |

---

## 3. Veri KaynaklarÄ±

### 3.1 Ä°Ã§ Kaynaklar (Internal Sources)

#### 3.1.1 Kurumsal Sistemler
1. **ERP (Enterprise Resource Planning)**
   - SAP, Oracle ERP
   - Finans, Ä°nsan KaynaklarÄ±, Ãœretim verileri
   - YÃ¼ksek veri kalitesi, doÄŸruluÄŸu

2. **CRM (Customer Relationship Management)**
   - Salesforce, Microsoft Dynamics
   - MÃ¼ÅŸteri bilgileri, satÄ±ÅŸ, destek kayÄ±tlarÄ±
   - MÃ¼ÅŸteri yaÅŸam dÃ¶ngÃ¼sÃ¼ analizi

3. **Ä°ÅŸlem Sistemleri (Transactional Systems)**
   - POS (Point of Sale) sistemleri
   - E-ticaret platformlarÄ±
   - Banka iÅŸlemleri
   - GerÃ§ek zamanlÄ± veri

4. **Operasyonel VeritabanlarÄ±**
   - Ãœretim veritabanlarÄ±
   - GÃ¼nlÃ¼k operasyonlar
   - OLTP sistemleri

#### 3.1.2 IoT ve SensÃ¶rler
- Fabrika sensÃ¶rleri (sÄ±caklÄ±k, basÄ±nÃ§, titreÅŸim)
- AkÄ±llÄ± cihazlar (smartwatch, fitness tracker)
- AraÃ§ telematiÄŸi
- AkÄ±llÄ± bina sistemleri
- **Ã–zellik:** YÃ¼ksek hacim, gerÃ§ek zamanlÄ±

#### 3.1.3 Log DosyalarÄ±
```log
2025-01-29 10:15:32 INFO User logged in: user_id=12345
2025-01-29 10:15:45 DEBUG Query executed: SELECT * FROM products
2025-01-29 10:16:01 ERROR Database connection failed: timeout
2025-01-29 10:16:15 WARN High memory usage: 85%
```

**TÃ¼rler:**
- Uygulama loglarÄ±
- Web server loglarÄ± (Apache, Nginx)
- VeritabanÄ± loglarÄ±
- GÃ¼venlik loglarÄ±

### 3.2 DÄ±ÅŸ Kaynaklar (External Sources)

#### 3.2.1 API'ler (Application Programming Interfaces)
```python
import requests

# Twitter API Ã¶rneÄŸi
response = requests.get(
    'https://api.twitter.com/2/tweets/search/recent',
    params={'query': 'data science'},
    headers={'Authorization': 'Bearer YOUR_TOKEN'}
)
tweets = response.json()
```

**PopÃ¼ler API'ler:**
- Twitter API (sosyal medya verileri)
- Google Maps API (konum verileri)
- OpenWeather API (hava durumu)
- Alpha Vantage (finans verileri)
- REST ve GraphQL API'ler

#### 3.2.2 Web Scraping
```python
from bs4 import BeautifulSoup
import requests

# Basit web scraping Ã¶rneÄŸi
url = 'https://example.com/products'
response = requests.get(url)
soup = BeautifulSoup(response.content, 'html.parser')

products = []
for item in soup.find_all('div', class_='product'):
    name = item.find('h2').text
    price = item.find('span', class_='price').text
    products.append({'name': name, 'price': price})
```

**Dikkat:** 
- Robots.txt dosyasÄ±na uyun
- Rate limiting uygulayÄ±n
- Telif haklarÄ± ve gizlilik

#### 3.2.3 AÃ§Ä±k Veri (Open Data)
**Kamu KaynaklarÄ±:**
- data.gov (ABD)
- data.gov.tr (TÃ¼rkiye)
- Eurostat (Avrupa)
- DÃ¼nya BankasÄ±
- WHO (DÃ¼nya SaÄŸlÄ±k Ã–rgÃ¼tÃ¼)

**Veri Setleri:**
- NÃ¼fus istatistikleri
- Ekonomik gÃ¶stergeler
- SaÄŸlÄ±k verileri
- UlaÅŸÄ±m verileri
- EÄŸitim istatistikleri

#### 3.2.4 Sosyal Medya
- Twitter: GerÃ§ek zamanlÄ± haber, duygu analizi
- Facebook: KullanÄ±cÄ± davranÄ±ÅŸlarÄ±
- Instagram: GÃ¶rsel iÃ§erik analizi
- LinkedIn: Profesyonel network analizi
- Reddit: Topluluk analizleri

#### 3.2.5 ÃœÃ§Ã¼ncÃ¼ Parti Veri SaÄŸlayÄ±cÄ±lar
- Nielsen (pazar araÅŸtÄ±rmasÄ±)
- Experian (kredi verileri)
- Bloomberg (finans verileri)
- Yelp (iÅŸletme deÄŸerlendirmeleri)

### 3.3 Veri Toplama YÃ¶ntemleri

#### GerÃ§ek ZamanlÄ± (Real-Time / Streaming)
- **Ã–zellik:** AnlÄ±k veri akÄ±ÅŸÄ±
- **Teknolojiler:** Apache Kafka, Amazon Kinesis
- **KullanÄ±m:** Borsa, IoT, fraud detection
- **Latency:** Milisaniyeler

#### Toplu (Batch)
- **Ã–zellik:** Belirli aralÄ±klarla toplanan veri
- **Teknolojiler:** Cron jobs, Apache Airflow
- **KullanÄ±m:** GÃ¼nlÃ¼k raporlar, ETL
- **Latency:** Saatler/gÃ¼nler

---

## 4. Veri PlatformlarÄ±nÄ±n Tarihsel Evrimi

### 4.1 1960'lar - Ä°lk VeritabanÄ± Sistemleri

#### HiyerarÅŸik VeritabanlarÄ±
- **IBM IMS (Information Management System)** - 1966
- Tree yapÄ±sÄ±: Parent-child iliÅŸkileri
- Sadece mainframe bilgisayarlarda
- Apollo programÄ± iÃ§in geliÅŸtirildi

```
         MÃ¼ÅŸteri (Parent)
           /        \
      SipariÅŸ    SipariÅŸ (Children)
        /           \
    ÃœrÃ¼n          ÃœrÃ¼n
```

#### AÄŸ VeritabanlarÄ± (Network Databases)
- **CODASYL** standardÄ±
- Daha esnek iliÅŸkiler (many-to-many)
- KarmaÅŸÄ±k navigasyon

**Sorunlar:**
- Esneklik dÃ¼ÅŸÃ¼k
- Programlama karmaÅŸÄ±k
- Veri baÄŸÄ±msÄ±zlÄ±ÄŸÄ± yok

### 4.2 1970-1980'ler - Ä°liÅŸkisel VeritabanlarÄ± Devrimi

#### Edgar F. Codd - Ä°liÅŸkisel Model (1970)
**Manifesto:** "A Relational Model of Data for Large Shared Data Banks"

**Temel Prensipler:**
1. Veriler tablolarda (relations) saklanÄ±r
2. Matematiksel kÃ¼me teorisi
3. Veri baÄŸÄ±msÄ±zlÄ±ÄŸÄ±
4. Bildirimsel sorgulama (SQL)

#### SQL'in DoÄŸuÅŸu
```sql
-- Ä°lk SQL sorgularÄ± (1970'ler)
SELECT customer_name, order_total
FROM customers, orders
WHERE customers.id = orders.customer_id
AND order_date > '1975-01-01';
```

#### Ã–nemli Sistemler:
- **Oracle Database** (1979) - Larry Ellison
- **IBM DB2** (1983)
- **Microsoft SQL Server** (1989)
- **PostgreSQL** (1986 - akademik, 1996 aÃ§Ä±k kaynak)

#### ACID KavramÄ±nÄ±n Standardizasyonu
- **1983:** Jim Gray tarafÄ±ndan formalize edildi
- Transaction gÃ¼venliÄŸi
- Veri tutarlÄ±lÄ±ÄŸÄ± garantisi

**Etki:**
- Veri yÃ¶netiminde devrim
- EndÃ¼stri standardÄ±
- GÃ¼nÃ¼mÃ¼zde hala dominant

### 4.3 1990-2000'ler - Veri AmbarlarÄ± ve Ä°ÅŸ ZekasÄ±

#### Data Warehouse Ã‡aÄŸÄ±
**Bill Inmon (1990):** "Building the Data Warehouse"
- Subject-oriented
- Integrated
- Time-variant
- Non-volatile

#### OLAP KÃ¼pleri
- Ã‡ok boyutlu analiz
- Slice, dice, drill-down
- Microsoft Analysis Services
- Oracle OLAP

#### ETL AraÃ§larÄ±
- Informatica
- IBM DataStage
- Oracle Data Integrator

#### Ä°ÅŸ ZekasÄ± PatlamasÄ±
- Crystal Reports
- Business Objects
- Cognos
- MicroStrategy

**KullanÄ±m SenaryolarÄ±:**
- SatÄ±ÅŸ analizleri
- Finansal raporlama
- Executive dashboards

### 4.4 2000'ler SonrasÄ± - Big Data ve NoSQL

#### Big Data'nÄ±n DoÄŸuÅŸu

**2003-2004: Google Makaleleri**
1. **Google File System (GFS)**
2. **MapReduce**
3. **BigTable**

```
Veri Hacmi: Gigabyte â†’ Terabyte â†’ Petabyte
```

**3V Modeli (Doug Laney, 2001):**
1. **Volume:** Veri miktarÄ± (petabyte'lar)
2. **Velocity:** Veri hÄ±zÄ± (gerÃ§ek zamanlÄ±)
3. **Variety:** Veri Ã§eÅŸitliliÄŸi (yapÄ±sal, yarÄ±, yapÄ±sal olmayan)

#### Apache Hadoop (2006)
- AÃ§Ä±k kaynak MapReduce implementasyonu
- HDFS (Hadoop Distributed File System)
- Commodity hardware Ã¼zerinde Ã§alÄ±ÅŸÄ±r
- Yahoo!, Facebook'ta kullanÄ±mÄ±

#### NoSQL Hareketi
**2009:** "NoSQL" terimi popÃ¼lerleÅŸir

**Motivasyon:**
- Web Ã¶lÃ§eÄŸinde uygulamalar (Google, Facebook, Amazon)
- Yatay Ã¶lÃ§eklenebilirlik ihtiyacÄ±
- Esnek ÅŸema gereksinimleri
- ACID'den Ã¶dÃ¼n verme (CAP teoremi)

**Ã–nemli NoSQL Sistemleri:**
- **MongoDB** (2009) - Document Store
- **Cassandra** (2008, Apache 2010) - Column-family
- **Redis** (2009) - Key-Value
- **Neo4j** (2007) - Graph Database

### 4.5 2010'lar - Bulut ve Modern Mimariler

#### Bulut Veri PlatformlarÄ±
**2006:** Amazon AWS lansmanÄ±
- **S3:** Object storage
- **EC2:** Compute
- **RDS:** Managed databases

**DBaaS (Database as a Service):**
- Amazon RDS, DynamoDB, Redshift
- Google BigQuery, Cloud Spanner
- Azure SQL Database, Cosmos DB

**Avantajlar:**
- Elastik Ã¶lÃ§eklenebilirlik
- KullandÄ±ÄŸÄ±n kadar Ã¶de
- YÃ¶netim yÃ¼kÃ¼ azalÄ±r

#### Data Lake KavramÄ± (2010)
**James Dixon (Pentaho):** "Data Pond" terimi

**Ã–zellikler:**
- Ham veri depolama
- Schema-on-read
- DÃ¼ÅŸÃ¼k maliyet (object storage)
- Big Data analytics

**Teknolojiler:**
- Amazon S3
- Azure Data Lake
- Hadoop HDFS

#### Streaming ve Real-Time
- **Apache Kafka** (2011, LinkedIn)
- **Apache Spark** (2012, Berkeley)
- **Apache Flink** (2014)

#### NewSQL (2010'lar)
- **Google Spanner** (2012)
- **CockroachDB** (2015)
- **TiDB** (2016)

**AmaÃ§:** ACID + Ã–lÃ§eklenebilirlik

### 4.6 2015-2025 - Modern Veri Ekosistemi

#### Data Lakehouse (2020+)
- Data Lake + Data Warehouse
- **Delta Lake** (Databricks)
- **Apache Iceberg** (Netflix)
- **Apache Hudi** (Uber)

#### Modern Data Stack
- **Ingestion:** Fivetran, Airbyte
- **Storage:** Snowflake, BigQuery, Databricks
- **Transformation:** dbt
- **Visualization:** Looker, Tableau, Power BI
- **Orchestration:** Apache Airflow, Prefect

#### Data Mesh (2019)
**Zhamak Dehghani:** Merkeziyetsiz veri sahipliÄŸi
- Domain-oriented
- Data as a product
- Self-serve platform
- Federated governance

#### AI/ML Entegrasyonu
- AutoML platformlarÄ±
- Feature stores
- ML pipelines
- MLOps

#### GerÃ§ek ZamanlÄ± Analitik
- Materialized views
- Streaming SQL
- Lambda/Kappa mimarileri

### 4.7 Evrim Ã–zeti Timeline

```
1960 â”â”â”â”â”â” HiyerarÅŸik/AÄŸ DB
1970 â”â”â”â”â”â” Ä°liÅŸkisel Model & SQL
1980 â”â”â”â”â”â” RDBMS OlgunlaÅŸmasÄ±
1990 â”â”â”â”â”â” Data Warehouse & OLAP
2000 â”â”â”â”â”â” Big Data & Hadoop
2005 â”â”â”â”â”â” NoSQL Hareketi
2010 â”â”â”â”â”â” Cloud & Data Lake
2015 â”â”â”â”â”â” Streaming & Real-time
2020 â”â”â”â”â”â” Lakehouse & Data Mesh
2025 â”â”â”â”â”â” AI-Native Platforms
```

---

## 5. Pratik Uygulamalar

### 5.1 Veri TÃ¼rlerini KeÅŸfetme

#### Python ile CSV Okuma (YapÄ±sal Veri)
```python
import pandas as pd

# CSV dosyasÄ±nÄ± oku
df = pd.read_csv('customers.csv')

# Ä°lk 5 satÄ±rÄ± gÃ¶rÃ¼ntÃ¼le
print(df.head())

# Veri tiplerine bak
print(df.dtypes)

# Temel istatistikler
print(df.describe())

# Eksik deÄŸerleri kontrol et
print(df.isnull().sum())
```

#### JSON ile Ã‡alÄ±ÅŸma (YarÄ±-YapÄ±sal Veri)
```python
import json
import pandas as pd

# JSON dosyasÄ±nÄ± oku
with open('api_response.json', 'r', encoding='utf-8') as f:
    data = json.load(f)

# Ä°Ã§eriÄŸi gÃ¶rÃ¼ntÃ¼le
print(json.dumps(data, indent=2, ensure_ascii=False))

# Nested verilere eriÅŸim
print(data['musteri']['iletisim']['email'])

# DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼r
df = pd.json_normalize(data)
print(df.head())

# Nested JSON'u dÃ¼zleÅŸtirme
flat_df = pd.json_normalize(
    data,
    record_path=['siparisler', 'urunler'],
    meta=['ad', 'soyad', ['iletisim', 'email']],
    meta_prefix='musteri_'
)
```

#### XML ile Ã‡alÄ±ÅŸma
```python
import xml.etree.ElementTree as ET

# XML parse etme
tree = ET.parse('config.xml')
root = tree.getroot()

# Element'lere eriÅŸim
for item in root.findall('.//product'):
    name = item.find('name').text
    price = item.find('price').text
    print(f"{name}: {price}")

# XML'den DataFrame'e
import pandas as pd
import xml.etree.ElementTree as ET

tree = ET.parse('products.xml')
root = tree.getroot()

data = []
for product in root.findall('.//product'):
    data.append({
        'id': product.find('id').text,
        'name': product.find('name').text,
        'price': float(product.find('price').text)
    })

df = pd.DataFrame(data)
print(df)
```

#### YapÄ±sal Olmayan Veri ile Ã‡alÄ±ÅŸma
```python
from PIL import Image
import PyPDF2
from pathlib import Path

# GÃ¶rÃ¼ntÃ¼ iÅŸleme
img = Image.open('product.jpg')
print(f"Boyut: {img.size}, Format: {img.format}")

# GÃ¶rÃ¼ntÃ¼ bilgileri
print(f"Mod: {img.mode}")  # RGB, RGBA, vb.
print(f"Dosya boyutu: {Path('product.jpg').stat().st_size / 1024:.2f} KB")

# PDF okuma
with open('document.pdf', 'rb') as f:
    pdf = PyPDF2.PdfReader(f)
    num_pages = len(pdf.pages)
    print(f"Sayfa sayÄ±sÄ±: {num_pages}")
    
    # Ä°lk sayfayÄ± oku
    text = pdf.pages[0].extract_text()
    print(text[:500])  # Ä°lk 500 karakter

# Metin analizi
from collections import Counter

words = text.lower().split()
word_count = len(words)
unique_words = len(set(words))
most_common = Counter(words).most_common(10)

print(f"\nToplam kelime: {word_count}")
print(f"Benzersiz kelime: {unique_words}")
print("\nEn sÄ±k kullanÄ±lan 10 kelime:")
for word, count in most_common:
    print(f"  {word}: {count}")

# Word belgeleri (.docx)
try:
    from docx import Document
    
    doc = Document('document.docx')
    
    # ParagraflarÄ± oku
    for para in doc.paragraphs[:5]:  # Ä°lk 5 paragraf
        print(para.text)
    
    # Tablo varsa oku
    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                print(cell.text, end='\t')
            print()
except ImportError:
    print("python-docx kÃ¼tÃ¼phanesi gerekli: pip install python-docx")
```

### 5.2 Veri Kalitesi KontrolÃ¼

```python
import pandas as pd
import numpy as np

def veri_kalitesi_raporu(df):
    """KapsamlÄ± veri kalitesi raporu"""
    
    print("=" * 50)
    print("VERÄ° KALÄ°TESÄ° RAPORU")
    print("=" * 50)
    
    # 1. Temel Bilgiler
    print(f"\n1. GENEL BÄ°LGÄ°LER")
    print(f"   Toplam SatÄ±r: {len(df)}")
    print(f"   Toplam SÃ¼tun: {len(df.columns)}")
    print(f"   Bellek KullanÄ±mÄ±: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
    
    # 2. Eksik DeÄŸerler
    print(f"\n2. EKSÄ°K DEÄERLER")
    eksik = df.isnull().sum()
    eksik_oran = (eksik / len(df) * 100).round(2)
    eksik_rapor = pd.DataFrame({
        'Eksik SayÄ±sÄ±': eksik,
        'Eksik OranÄ± (%)': eksik_oran
    })
    print(eksik_rapor[eksik_rapor['Eksik SayÄ±sÄ±'] > 0])
    
    # 3. Tekrar Eden KayÄ±tlar
    print(f"\n3. TEKRAR EDEN KAYITLAR")
    duplicates = df.duplicated().sum()
    print(f"   Tekrar Eden SatÄ±r: {duplicates} ({duplicates/len(df)*100:.2f}%)")
    
    # 4. Veri Tipleri
    print(f"\n4. VERÄ° TÄ°PLERÄ°")
    print(df.dtypes.value_counts())
    
    # 5. SayÄ±sal SÃ¼tunlar iÃ§in Ä°statistikler
    print(f"\n5. SAYISAL SÃœTUN Ä°STATÄ°STÄ°KLERÄ°")
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    if len(numeric_cols) > 0:
        print(df[numeric_cols].describe())
    
    # 6. Kategorik SÃ¼tunlar
    print(f"\n6. KATEGORÄ°K SÃœTUNLAR")
    categorical_cols = df.select_dtypes(include=['object']).columns
    for col in categorical_cols[:5]:  # Ä°lk 5 kategorik sÃ¼tun
        print(f"\n   {col}:")
        print(f"   Benzersiz DeÄŸer: {df[col].nunique()}")
        print(f"   En SÄ±k 3 DeÄŸer:\n{df[col].value_counts().head(3)}")
    
    # 7. Outlier KontrolÃ¼ (IQR yÃ¶ntemi)
    print(f"\n7. OUTLIER KONTROLÃœ (IQR)")
    for col in numeric_cols:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
        if len(outliers) > 0:
            print(f"   {col}: {len(outliers)} outlier ({len(outliers)/len(df)*100:.2f}%)")

# KullanÄ±m
df = pd.read_csv('sample_data.csv')
veri_kalitesi_raporu(df)
```

### 5.3 FarklÄ± Veri KaynaklarÄ±ndan Veri Ã‡ekme

#### API'den Veri Ã‡ekme
```python
import requests
import pandas as pd

def get_weather_data(city):
    """OpenWeather API'den hava durumu verisi Ã§ek"""
    api_key = "YOUR_API_KEY"
    url = f"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={api_key}&units=metric"
    
    response = requests.get(url)
    if response.status_code == 200:
        data = response.json()
        return {
            'city': data['name'],
            'temperature': data['main']['temp'],
            'humidity': data['main']['humidity'],
            'description': data['weather'][0]['description']
        }
    return None

# Birden fazla ÅŸehir iÃ§in veri topla
cities = ['Istanbul', 'Ankara', 'Izmir']
weather_data = [get_weather_data(city) for city in cities]
df_weather = pd.DataFrame(weather_data)
print(df_weather)
```

#### VeritabanÄ±ndan Veri Ã‡ekme
```python
import psycopg2
import pandas as pd

# PostgreSQL baÄŸlantÄ±sÄ±
conn = psycopg2.connect(
    host="localhost",
    database="veri_db",
    user="veri_user",
    password="veri_pass"
)

# SQL sorgusu ile veri Ã§ek
query = """
SELECT 
    DATE(order_date) as date,
    COUNT(*) as order_count,
    SUM(total_amount) as revenue
FROM orders
WHERE order_date >= CURRENT_DATE - INTERVAL '30 days'
GROUP BY DATE(order_date)
ORDER BY date;
"""

df = pd.read_sql(query, conn)
conn.close()

print(df)
```

---

## 6. AlÄ±ÅŸtÄ±rmalar

```markdown
# Hafta 1: Veri DÃ¼nyasÄ±na GiriÅŸ - Pratik Uygulama

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### AdÄ±m 1: Projeyi KlonlayÄ±n veya Ä°ndirin

```bash
cd veri-platformlari-egitim/week1-intro
```

### AdÄ±m 2: Docker Container'Ä± BaÅŸlatÄ±n

```bash
# Container'Ä± build et ve baÅŸlat
docker-compose up --build -d

# LoglarÄ± izle
docker-compose logs -f
```

### AdÄ±m 3: Jupyter Lab'e EriÅŸin

TarayÄ±cÄ±nÄ±zda aÃ§Ä±n: **http://localhost:8888**

### AdÄ±m 4: Ã–rnek Veri OluÅŸturun

Jupyter terminal'de:

```bash
python /app/scripts/generate_sample_data.py
```

### AdÄ±m 5: Veri Kalitesi KontrolÃ¼

```bash
python /app/scripts/data_quality_checker.py
```

## ğŸ“š Jupyter Notebook'larÄ±

1. **01-data-types-exploration.ipynb** - Veri tÃ¼rlerini keÅŸfedin
2. **02-data-quality-check.ipynb** - Veri kalitesi analizi
3. **03-data-sources-demo.ipynb** - FarklÄ± kaynaklardan veri Ã§ekme

## ğŸ› ï¸ YararlÄ± Komutlar

```bash
# Container'a shell ile baÄŸlan
docker exec -it week1_jupyter bash

# Container'Ä± durdur
docker-compose down

# Container'Ä± sil (volumes dahil)
docker-compose down -v

# LoglarÄ± gÃ¶rÃ¼ntÃ¼le
docker-compose logs jupyter

# Container'Ä± yeniden baÅŸlat
docker-compose restart
```

## ğŸ“Š OluÅŸturulan Veri DosyalarÄ±

- `data-samples/structured/customers.csv` - 1,000 mÃ¼ÅŸteri
- `data-samples/structured/sales.csv` - 5,000 satÄ±ÅŸ kaydÄ±
- `data-samples/structured/products.csv` - 200 Ã¼rÃ¼n
- `data-samples/semi-structured/api-response.json` - API yanÄ±tÄ±
- `data-samples/semi-structured/config.xml` - XML config
- `data-samples/unstructured/sample.txt` - Metin dosyasÄ±

## ğŸ¯ Ã–ÄŸrenme Hedefleri

âœ… FarklÄ± veri tÃ¼rlerini tanÄ±ma ve iÅŸleme  
âœ… Veri kalitesi kontrolÃ¼ yapma  
âœ… Python ile veri analizi  
âœ… Pandas, NumPy, Matplotlib kullanÄ±mÄ±  
âœ… Docker environment'Ä±nda Ã§alÄ±ÅŸma  


---

## 7. Kaynaklar

### Temel Okumalar
1. **"The Data Warehouse Toolkit"** - Ralph Kimball
2. **"Designing Data-Intensive Applications"** - Martin Kleppmann
3. **"Big Data: Principles and Best Practices"** - Nathan Marz

### Online Kaynaklar
- [Kaggle Learn - Intro to SQL](https://www.kaggle.com/learn/intro-to-sql)
- [Data Science Central](https://www.datasciencecentral.com/)
- [Towards Data Science (Medium)](https://towardsdatascience.com/)

### Videolar
- [What is Data?](https://www.youtube.com/watch?v=...)
- [History of Databases](https://www.youtube.com/watch?v=...)
- [Structured vs Unstructured Data](https://www.youtube.com/watch?v=...)

### Makaleler
1. **Edgar F. Codd (1970)** - "A Relational Model of Data for Large Shared Data Banks"
2. **Google (2003)** - "The Google File System"
3. **Google (2004)** - "MapReduce: Simplified Data Processing on Large Clusters"

### Veri Setleri Pratik Ä°Ã§in
- [Kaggle Datasets](https://www.kaggle.com/datasets)
- [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/)
- [Data.gov](https://data.gov/)
- [Google Dataset Search](https://datasetsearch.research.google.com/)

### AraÃ§lar
- **Jupyter Notebook** - Ä°nteraktif Python
- **DBeaver** - Universal database tool
- **Tableau Public** - Ãœcretsiz gÃ¶rselleÅŸtirme
- **Google Colab** - Bulut tabanlÄ± notebook

---

## ğŸ“ Hafta Ã–zeti

Bu haftada Ã¶ÄŸrendiklerimiz:

âœ… **Veri KavramÄ±:** Veri, bilgi ve bilgi arasÄ±ndaki farklar  
âœ… **Veri TÃ¼rleri:** YapÄ±sal, yarÄ±-yapÄ±sal, yapÄ±sal olmayan veri  
âœ… **Veri KaynaklarÄ±:** Ä°Ã§ ve dÄ±ÅŸ kaynaklardan veri toplama  
âœ… **Tarihsel Evrim:** 1960'lardan gÃ¼nÃ¼mÃ¼ze veri platformlarÄ±nÄ±n geliÅŸimi  
âœ… **Pratik Beceriler:** Python ile veri okuma, analiz ve kalite kontrolÃ¼



## ğŸ’¡ Ã–nemli Notlar

> **Veri Kalitesi:** "Garbage in, garbage out" - Kalitesiz veri, kalitesiz sonuÃ§lar Ã¼retir.

> **Veri GÃ¼venliÄŸi:** GDPR, KVKK gibi dÃ¼zenlemelere uyum kritik Ã¶neme sahiptir.

> **Ã–lÃ§eklenebilirlik:** BugÃ¼nkÃ¼ veri hacmi yarÄ±nÄ±n veri hacmi deÄŸildir. Ä°leriye dÃ¶nÃ¼k planlayÄ±n.

---


[â† Ana Sayfaya DÃ¶n](../README.md) | [Hafta 2'e Git â†’](../week2-rdms/README.md)**

