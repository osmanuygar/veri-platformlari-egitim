# ETL Service - Extract, Transform, Load

Week 4 Data Warehouse projesi iÃ§in ETL (Extract, Transform, Load) servisi.

## ğŸ“ KlasÃ¶r YapÄ±sÄ±

```
etl/
â”œâ”€â”€ README.md              # Bu dosya
â”œâ”€â”€ Dockerfile            # ETL container image
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ python/              # Python ETL scripts
    â”œâ”€â”€ config.py        # YapÄ±landÄ±rma modÃ¼lÃ¼
    â”œâ”€â”€ extract.py       # Extract: OLTP'den veri Ã§ekme
    â”œâ”€â”€ transform.py     # Transform: Veri dÃ¶nÃ¼ÅŸtÃ¼rme
    â”œâ”€â”€ load.py          # Load: OLAP'a ve Data Lake'e yÃ¼kleme
    â””â”€â”€ full_pipeline.py # Tam pipeline orchestration
```

## ğŸ¯ ETL SÃ¼reci

### 1. **Extract (Ã‡Ä±karma)**
OLTP veritabanÄ±ndan veri Ã§eker:
- `customers` - MÃ¼ÅŸteri bilgileri
- `products` - ÃœrÃ¼n katalog
- `categories` - Kategori hiyerarÅŸisi
- `orders` - SipariÅŸ baÅŸlÄ±klarÄ±
- `order_items` - SipariÅŸ detaylarÄ±
- `addresses` - Adres bilgileri
- `payment_methods` - Ã–deme yÃ¶ntemleri

### 2. **Transform (DÃ¶nÃ¼ÅŸtÃ¼rme)**
Verileri dimensional model'e dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r:

#### Dimension Tables
- `dim_customer` - MÃ¼ÅŸteri dimensiyonu
- `dim_product` - ÃœrÃ¼n dimensiyonu
- `dim_category` - Kategori dimensiyonu
- `dim_date` - Tarih dimensiyonu

#### Fact Tables
- `fact_sales` - SatÄ±ÅŸ fact tablosu
- `fact_inventory` - Envanter snapshot'Ä±

### 3. **Load (YÃ¼kleme)**
Ä°ki hedefe yÃ¼kler:
- **OLAP Database**: PostgreSQL data warehouse
- **Data Lake**: MinIO/S3 (Parquet format)

## ğŸš€ KullanÄ±m

### Tek Seferlik Ã‡alÄ±ÅŸtÄ±rma

```bash
# Docker Compose ile
docker-compose run --rm etl

# Manuel olarak
cd python
python full_pipeline.py
```

### SÃ¼rekli Ã‡alÄ±ÅŸtÄ±rma (Scheduled)

```bash
# Docker Compose ile (5 dakikada bir)
docker-compose --profile etl up -d etl

# Manuel olarak
cd python
ETL_RUN_MODE=continuous python full_pipeline.py
```

### Environment Variables

```bash
# OLTP (Source)
OLTP_HOST=postgres-oltp
OLTP_PORT=5432
OLTP_DB=ecommerce_oltp
OLTP_USER=oltp_user
OLTP_PASSWORD=oltp_pass123

# OLAP (Target)
OLAP_HOST=postgres-olap
OLAP_PORT=5432
OLAP_DB=ecommerce_dw
OLAP_USER=olap_user
OLAP_PASSWORD=olap_pass123

# MinIO (Data Lake)
MINIO_ENDPOINT=minio:9000
MINIO_ROOT_USER=minio_admin
MINIO_ROOT_PASSWORD=minio_password123
MINIO_BUCKET=datawarehouse

# ETL Settings
ETL_RUN_MODE=continuous        # once | continuous
ETL_INTERVAL_SECONDS=300       # 5 minutes
ETL_BATCH_SIZE=1000
```

## ğŸ“Š ModÃ¼ller DetayÄ±

### config.py
YapÄ±landÄ±rma yÃ¶netimi:
- Database baÄŸlantÄ± ayarlarÄ±
- MinIO/S3 yapÄ±landÄ±rmasÄ±
- ETL Ã§alÄ±ÅŸma modu ve aralÄ±klarÄ±
- Logging setup

```python
from config import config, logger

# KullanÄ±m
print(config.oltp.host)
logger.info("ETL started")
```

### extract.py
OLTP'den veri Ã§ekme:
- Tam tablo Ã§ekme (full load)
- ArtÄ±rÄ±mlÄ± Ã§ekme (incremental load)
- Ã–zel sorgular
- Tablo istatistikleri

```python
from extract import OLTPExtractor

extractor = OLTPExtractor()
extractor.connect()

# TÃ¼m mÃ¼ÅŸterileri Ã§ek
customers = extractor.extract_customers()

# Son 24 saatteki deÄŸiÅŸiklikleri Ã§ek
new_orders = extractor.extract_incremental(
    'orders', 
    'updated_at',
    last_extract_time
)

extractor.disconnect()
```

### transform.py
Veri dÃ¶nÃ¼ÅŸtÃ¼rme iÅŸlemleri:
- OLTP â†’ Dimensional Model dÃ¶nÃ¼ÅŸÃ¼mÃ¼
- HesaplanmÄ±ÅŸ alanlar ekleme
- Veri temizleme ve normalizasyon
- Validasyon

```python
from transform import DataTransformer

transformer = DataTransformer()

# MÃ¼ÅŸteri dimensiyonuna dÃ¶nÃ¼ÅŸtÃ¼r
dim_customer = transformer.transform_dim_customer(customers_df)

# SatÄ±ÅŸ fact tablosuna dÃ¶nÃ¼ÅŸtÃ¼r
fact_sales = transformer.transform_fact_sales(order_items_df)

# TÃ¼m dÃ¶nÃ¼ÅŸÃ¼mleri yap
all_transformed = transformer.transform_all(extracted_data)

# Validasyon
is_valid = transformer.validate_transformations(all_transformed)
```

### load.py
OLAP ve Data Lake'e yÃ¼kleme:
- Bulk insert (hÄ±zlÄ± yÃ¼kleme)
- COPY komutu (Ã§ok bÃ¼yÃ¼k veri iÃ§in)
- Upsert (gÃ¼ncelleme/ekleme)
- Parquet formatÄ±nda arÅŸivleme

```python
from load import ETLLoader

loader = ETLLoader()
loader.connect_all()

# Dimension yÃ¼kle
loader.load_dimension(dim_customer_df, 'dim_customer')

# Fact yÃ¼kle
loader.load_fact(fact_sales_df, 'fact_sales')

# TÃ¼mÃ¼nÃ¼ yÃ¼kle
loader.load_all(transformed_data)

loader.disconnect_all()
```

### full_pipeline.py
Tam ETL orchestration:
- Connect â†’ Extract â†’ Transform â†’ Load â†’ Disconnect
- Hata yÃ¶netimi
- Loglama
- Ä°statistikler

```python
from full_pipeline import ETLPipeline

pipeline = ETLPipeline()

# Tek seferlik Ã§alÄ±ÅŸtÄ±r
pipeline.run_once()

# SÃ¼rekli Ã§alÄ±ÅŸtÄ±r (5 dakikada bir)
pipeline.run_continuous(interval_seconds=300)
```

## ğŸ” ETL Ä°zleme

### Console Logs
ETL Ã§alÄ±ÅŸÄ±rken renkli loglar gÃ¶rÃ¼rsÃ¼nÃ¼z:
- ğŸŸ¢ **INFO**: Normal iÅŸlemler
- ğŸŸ¡ **WARNING**: UyarÄ±lar
- ğŸ”´ **ERROR**: Hatalar
- âœ“ BaÅŸarÄ±lÄ± iÅŸlemler
- âœ— BaÅŸarÄ±sÄ±z iÅŸlemler

### Log DosyalarÄ±
```bash
# ETL loglarÄ±nÄ± gÃ¶rÃ¼ntÃ¼le
docker logs -f etl_service

# Son 100 satÄ±r
docker logs --tail 100 etl_service

# Belirli tarihten itibaren
docker logs --since "2024-01-01T00:00:00" etl_service
```

## ğŸ“ˆ Performans

### Optimize EdilmiÅŸ YÃ¼kleme Stratejileri

1. **KÃ¼Ã§Ã¼k veri (<10K satÄ±r)**: Bulk insert
2. **BÃ¼yÃ¼k veri (>10K satÄ±r)**: COPY komutu
3. **ArtÄ±rÄ±mlÄ±**: Upsert ile merge

### Benchmark (Ã¶rnek)
```
Extract Phase:   ~5 seconds  (50K rows)
Transform Phase: ~3 seconds  (data processing)
Load Phase:      ~7 seconds  (OLAP + Data Lake)
Total:          ~15 seconds
```

## ğŸ§ª Test Etme

### Manuel Test

```bash
# Extract modÃ¼lÃ¼nÃ¼ test et
cd python
python extract.py

# Transform modÃ¼lÃ¼nÃ¼ test et
python transform.py

# Load modÃ¼lÃ¼nÃ¼ test et
python load.py

# Tam pipeline'Ä± test et
python full_pipeline.py
```

### Docker ile Test

```bash
# Tek seferlik test
docker-compose run --rm etl

# LoglarÄ± takip et
docker-compose --profile etl up etl
```

## ğŸ› ï¸ Troubleshooting

### Problem: BaÄŸlantÄ± hatasÄ±
```bash
# Database'lerin hazÄ±r olduÄŸunu kontrol et
docker ps | grep postgres

# Network baÄŸlantÄ±sÄ±nÄ± test et
docker exec etl_service ping postgres-oltp
```

### Problem: Transformation hatasÄ±
```python
# Veri kalitesini kontrol et
df.info()
df.describe()
df.isnull().sum()
```

### Problem: Load hatasÄ±
```bash
# OLAP database'i kontrol et
docker exec -it postgres_olap psql -U olap_user -d ecommerce_dw

# Tablo yapÄ±sÄ±nÄ± kontrol et
\d+ dim_customer
```

## ğŸ” GÃ¼venlik

### Best Practices
1. âœ… Environment variables kullan (ÅŸifreleri hardcode etme)
2. âœ… `.env` dosyasÄ±nÄ± `.gitignore`'a ekle
3. âœ… Production'da gÃ¼Ã§lÃ¼ ÅŸifreler kullan
4. âœ… MinIO iÃ§in SSL aktif et (production)
5. âœ… Database kullanÄ±cÄ±larÄ±na minimum yetki ver

### Production Checklist
```bash
# .env dosyasÄ±nÄ± gÃ¼ncelle
OLTP_PASSWORD=<strong-password>
OLAP_PASSWORD=<strong-password>
MINIO_ROOT_PASSWORD=<strong-password>

# SSL iÃ§in MinIO yapÄ±landÄ±r
MINIO_SECURE=true
```

## ğŸ“š Ã–ÄŸrenme KaynaklarÄ±

### ETL Best Practices
- [Kimball Group - ETL Best Practices](https://www.kimballgroup.com/)
- [Data Warehouse Toolkit](https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/books/)

### Python Data Engineering
- [Pandas Documentation](https://pandas.pydata.org/)
- [PostgreSQL COPY Command](https://www.postgresql.org/docs/current/sql-copy.html)
- [MinIO Python SDK](https://min.io/docs/minio/linux/developers/python/minio-py.html)

## ğŸ“ AlÄ±ÅŸtÄ±rmalar

### Temel Seviye
1. âœï¸ Yeni bir extract fonksiyonu ekle (Ã¶rn: `extract_top_customers`)
2. âœï¸ Transform'da yeni bir calculated field ekle
3. âœï¸ Log mesajlarÄ±nÄ± Ã¶zelleÅŸtir

### Orta Seviye
4. âœï¸ Incremental load stratejisi ekle
5. âœï¸ Hata durumunda retry mekanizmasÄ± ekle
6. âœï¸ Data quality check'leri ekle

### Ä°leri Seviye
7. âœï¸ Parallel processing ekle (Ã§oklu tablo aynÄ± anda)
8. âœï¸ Change Data Capture (CDC) implementasyonu
9. âœï¸ Slowly Changing Dimensions (SCD Type 2) ekle
10. âœï¸ Airflow DAG'e dÃ¶nÃ¼ÅŸtÃ¼r

## ğŸ¤ KatkÄ±da Bulunma

Bu ETL servisini geliÅŸtirmek iÃ§in:
1. Yeni transformation logic'leri ekleyin
2. Performans iyileÅŸtirmeleri yapÄ±n
3. Daha fazla veri kalite kontrolÃ¼ ekleyin
4. DokÃ¼mantasyonu iyileÅŸtirin

## ğŸ“ Notlar

### Ã–nemli HatÄ±rlatmalar
- ğŸ”´ **Production'da**: Incremental load kullanÄ±n (full load maliyetli)
- ğŸŸ¡ **Data Quality**: Her zaman transformation sonrasÄ± validasyon yapÄ±n
- ğŸŸ¢ **Monitoring**: Loglara dikkat edin, baÅŸarÄ±/baÅŸarÄ±sÄ±zlÄ±k oranlarÄ±nÄ± takip edin
- ğŸ”µ **Backup**: Data Lake'de tutulan parquet dosyalarÄ± backup olarak kullanÄ±labilir
